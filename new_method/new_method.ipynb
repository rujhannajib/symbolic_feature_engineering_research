{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6df302c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gplearn.genetic import SymbolicTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from pmlb import fetch_data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from npeet import entropy_estimators as ee\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcf92bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ur_with_npeet(x_k, y, z):\n",
    "    \"\"\"\n",
    "    Calculates the Unique Relevance (Conditional Mutual Information) I(x_k; y | z)\n",
    "    using the entropy-based chain rule and the npeet KSG estimator.\n",
    "\n",
    "    Formula: I(X;Y|Z) = H(X,Z) + H(Y,Z) - H(Z) - H(X,Y,Z)\n",
    "\n",
    "    Args:\n",
    "        x_k (pd.Series): The candidate feature vector.\n",
    "        y (pd.Series): The target vector.\n",
    "        z (pd.DataFrame): The conditioning set of all other features.\n",
    "\n",
    "    Returns:\n",
    "        float: The estimated conditional mutual information.\n",
    "    \"\"\"\n",
    "    # npeet expects numpy arrays of shape (n_samples, n_dimensions)\n",
    "    x_k_arr = x_k.values.reshape(-1, 1)\n",
    "    y_arr = y.values.reshape(-1, 1)\n",
    "    z_arr = z.values\n",
    "\n",
    "    # H(X,Z)\n",
    "    xz_entropy = ee.entropy(np.c_[x_k_arr, z_arr])\n",
    "    # H(Y,Z)\n",
    "    yz_entropy = ee.entropy(np.c_[y_arr, z_arr])\n",
    "    # H(Z)\n",
    "    z_entropy = ee.entropy(z_arr)\n",
    "    # H(X,Y,Z)\n",
    "    xyz_entropy = ee.entropy(np.c_[x_k_arr, y_arr, z_arr])\n",
    "\n",
    "    # The result must be non-negative\n",
    "    return max(0, xz_entropy + yz_entropy - z_entropy - xyz_entropy)\n",
    "\n",
    "\n",
    "def mrmr_bur_npeet(X: pd.DataFrame, y: pd.Series, K: int, beta: float = 0.1) -> list:\n",
    "    \"\"\"\n",
    "    Implements MRwMR-BUR using the npeet KSG estimator for ALL mutual\n",
    "    information and entropy calculations.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): The input feature matrix.\n",
    "        y (pd.Series): The target vector (can be discrete or continuous).\n",
    "        K (int): The number of features to select.\n",
    "        beta (float): The weighting factor for balancing mRMR and UR.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of the names of the K selected features.\n",
    "    \"\"\"\n",
    "    if not 0 <= beta <= 1:\n",
    "        raise ValueError(\"beta must be between 0 and 1.\")\n",
    "\n",
    "    # --- Step 1: Calculate Relevance using npeet ---\n",
    "    print(\"Calculating Relevance scores with npeet...\")\n",
    "    relevance_scores = pd.Series(\n",
    "        [ee.mi(X[[feature]].values, y.values.reshape(-1, 1)) for feature in X.columns],\n",
    "        index=X.columns\n",
    "    )\n",
    "\n",
    "    # --- Step 2: Calculate Unique Relevance (UR) using npeet ---\n",
    "    print(\"Calculating Unique Relevance for all features with npeet...\")\n",
    "    ur_scores = {}\n",
    "    for feature_k in X.columns:\n",
    "        Z = X.drop(columns=[feature_k])\n",
    "        ur_scores[feature_k] = calculate_ur_with_npeet(X[feature_k], y, Z)\n",
    "    ur_scores = pd.Series(ur_scores)\n",
    "    print(\"Unique Relevance calculation complete.\")\n",
    "\n",
    "    # --- Step 3: Initialize the selection process ---\n",
    "    selected_features = []\n",
    "    # Note: The first feature is now chosen based on the full MRwMR-BUR score\n",
    "    # This is a slight deviation but more aligned with a complete BUR approach\n",
    "    \n",
    "    # --- Step 4: Iteratively select all K features ---\n",
    "    remaining_features = X.columns.tolist()\n",
    "    \n",
    "    for i in range(K):\n",
    "        final_scores = {}\n",
    "        \n",
    "        for feature in remaining_features:\n",
    "            relevance = relevance_scores[feature]\n",
    "            ur_score = ur_scores[feature]\n",
    "\n",
    "            # Calculate Redundancy with already selected features using npeet\n",
    "            if i > 0:\n",
    "                redundancy_per_feature = [\n",
    "                    ee.mi(X[[feature]].values, X[[selected]].values) for selected in selected_features\n",
    "                ]\n",
    "                redundancy = np.mean(redundancy_per_feature)\n",
    "            else:\n",
    "                redundancy = 0 # No redundancy for the first feature\n",
    "\n",
    "            # The augmented scoring function from the paper\n",
    "            original_mrmr_score = relevance - redundancy\n",
    "            final_scores[feature] = (1 - beta) * original_mrmr_score + beta * ur_score\n",
    "\n",
    "        best_next_feature = max(final_scores, key=final_scores.get)\n",
    "        selected_features.append(best_next_feature)\n",
    "        remaining_features.remove(best_next_feature)\n",
    "\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c83c3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_feature_types(df, cardinality_threshold=5):\n",
    "    \"\"\"\n",
    "    Identifies categorical and numerical features in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        cardinality_threshold (int): The maximum number of unique values\n",
    "                                     for a numeric column to be considered\n",
    "                                     categorical.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two lists:\n",
    "               - categorical_features (list)\n",
    "               - numerical_features (list)\n",
    "    \"\"\"\n",
    "    categorical_features = []\n",
    "    numerical_features = []\n",
    "\n",
    "    for column in df.columns:\n",
    "        dtype = df[column].dtype\n",
    "        # Rule 1: Check for 'object' or 'category' data types\n",
    "        if dtype == 'object' or isinstance(dtype, pd.CategoricalDtype):\n",
    "            categorical_features.append(column)\n",
    "\n",
    "        # Rule 2: Check for numeric types\n",
    "        elif pd.api.types.is_numeric_dtype(df[column]):\n",
    "            # Check if it's a low-cardinality numeric column (likely categorical)\n",
    "            if df[column].nunique() < cardinality_threshold:\n",
    "                categorical_features.append(column)\n",
    "            else:\n",
    "                # High-cardinality numeric column (likely continuous or an ID)\n",
    "                numerical_features.append(column)\n",
    "        else:\n",
    "            # Handle other potential data types if necessary\n",
    "            pass # Or add to a separate list for review\n",
    "\n",
    "    return categorical_features, numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1feb4a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPForestFeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, gp_params=None, top_k_features=None, random_state=None):\n",
    "        self.gp_params = gp_params\n",
    "        self.top_k_features = top_k_features\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = pd.DataFrame(X, columns=[f\"feat_{i}\" for i in range(X.shape[1])])\n",
    "        \n",
    "        gp_params = self.gp_params.copy() if self.gp_params else {}\n",
    "        if 'random_state' not in gp_params and self.random_state is not None:\n",
    "            gp_params['random_state'] = self.random_state\n",
    "\n",
    "        self.gp = SymbolicTransformer(**gp_params)\n",
    "\n",
    "        # Identify feature types and store the list of numerical features\n",
    "        _, self.numerical_features_ = identify_feature_types(X) # <-- CHANGE: Store numerical feature names\n",
    "\n",
    "        # Fit on numerical features only\n",
    "        self.gp.fit(X[self.numerical_features_], y)\n",
    "\n",
    "        gp_features_array = self.gp.transform(X[self.numerical_features_])\n",
    "\n",
    "        # Store the names of the generated features for use in transform()\n",
    "        self.gp_feature_names_ = [f\"gp_feat_{i}\" for i in range(gp_features_array.shape[1])]\n",
    "        gp_features = pd.DataFrame(gp_features_array, \n",
    "                                     columns=self.gp_feature_names_, \n",
    "                                     index=X.index)\n",
    "\n",
    "        # Combine original data with new GP features for selection\n",
    "        X_combined = pd.concat([X, gp_features], axis=1)\n",
    "\n",
    "        # Select the best features from the combined set\n",
    "        self.final_feature_names_ = mrmr_bur_npeet(X=X_combined, y=y, K=self.top_k_features)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            # Ensure columns match what was seen in fit\n",
    "            X = pd.DataFrame(X, columns=[f\"feat_{i}\" for i in range(X.shape[1])])\n",
    "        \n",
    "        # --- FIX: Use the stored numerical_features_ list ---\n",
    "        gp_features_array = self.gp.transform(X[self.numerical_features_])\n",
    "        \n",
    "        # Use the stored GP feature names\n",
    "        gp_features = pd.DataFrame(gp_features_array, \n",
    "                                     columns=self.gp_feature_names_, \n",
    "                                     index=X.index)\n",
    "\n",
    "        # Combine original data with new GP features\n",
    "        X_combined = pd.concat([X, gp_features], axis=1)\n",
    "        \n",
    "        # Select the final features determined during fit\n",
    "        return X_combined[self.final_feature_names_] # <-- REFINEMENT: Return DataFrame\n",
    "    \n",
    "    def explain(self):\n",
    "        # Print best programs (optional)\n",
    "        print(\"Constructed features:\")\n",
    "        for i, program in enumerate(self.gp._best_programs):\n",
    "            print(f\"gp_feat_{i}: {program}\")\n",
    "        print(\"Final selected features:\")\n",
    "        for i, program in enumerate(self.feature_names_):\n",
    "            print(f\"{program}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f328bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "datasets = [\"allbp\", \"Hill_Valley_with_noise\",\"Hill_Valley_without_noise\",\"adult\",\"allhyper\",\"breast_cancer\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0ae863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_approach_benchmark(dataset_name, seed):\n",
    "    df = fetch_data(dataset_name)\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(df.drop([\"target\"], axis=\"columns\"), df[\"target\"], train_size = 0.8, stratify=df[\"target\"], random_state = SEED)\n",
    "\n",
    "    transformer = GPForestFeatureTransformer(gp_params={'generations': 10, 'population_size': 10000, 'hall_of_fame': 100, 'n_components': 10, \n",
    "                                                    'function_set' : ['add', 'sub', 'mul', 'div','sqrt', 'log', 'abs', 'neg', 'inv', 'max', 'min'],\n",
    "                                                    'parsimony_coefficient': 0.01, 'max_samples': 0.9, 'verbose': 1, 'random_state': SEED, 'n_jobs': 3, \n",
    "                                                    'metric': \"spearman\"}, top_k_features=(len(df.columns)+10) // 2, random_state=SEED)\n",
    "    \n",
    "    transformer.fit(X_train, y_train)\n",
    "    transformed_X_train = transformer.transform(X_train)\n",
    "    transformed_X_valid = transformer.transform(X_valid)\n",
    "\n",
    "    clf = RandomForestClassifier(random_state=seed)\n",
    "    clf.fit(transformed_X_train, y_train)\n",
    "    y_pred = clf.predict(transformed_X_valid)\n",
    "    acc = accuracy_score(y_valid, y_pred)\n",
    "    print(f\"Accuracy on {dataset_name}: {acc}\")\n",
    "    # transformer.explain()\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a664de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    12.63        0.0722931        7         0.304656        0.0213994     57.02s\n",
      "   1     4.03          0.15972       14         0.328537         0.220896     51.63s\n",
      "   2     2.86         0.190788       14         0.332976        0.0944118     44.32s\n",
      "   3     3.86         0.230595        3         0.327797        0.0489404     33.78s\n",
      "   4     3.12         0.242116        3         0.320954        0.0428614     26.30s\n",
      "   5     3.05         0.241312        3         0.323014        0.0122369     19.00s\n",
      "   6     3.05          0.24041        5         0.328458        0.0496743     13.00s\n",
      "   7     3.03         0.240531        3         0.322423        0.0431377      7.81s\n",
      "   8     3.01         0.238993        3         0.331325        0.0521459      4.65s\n",
      "   9     3.03         0.239873        3         0.321959         0.018159      0.00s\n",
      "Calculating Relevance scores with npeet...\n",
      "Calculating Unique Relevance for all features with npeet...\n",
      "Unique Relevance calculation complete.\n",
      "Accuracy on allbp: 0.9735099337748344\n",
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    10.20         0.069553        5         0.406259         0.424533     19.06s\n",
      "   1     3.44         0.129602       16         0.454927         0.289446     30.13s\n",
      "   2     3.47         0.217694        7         0.485595         0.593792     24.11s\n",
      "   3     3.85         0.233543       11         0.592408         0.555242     22.89s\n",
      "   4     5.13         0.228765       17         0.637786         0.642417     17.98s\n",
      "   5     6.62         0.265568       17         0.697361         0.642351     16.30s\n",
      "   6     9.43         0.342205       26         0.727047         0.669413     12.12s\n",
      "   7    12.17         0.394824       28         0.748063         0.596667      7.69s\n",
      "   8    14.03         0.432172       30         0.764101         0.678537      4.12s\n",
      "   9    14.49         0.434849       29         0.760599         0.791439      0.00s\n",
      "Calculating Relevance scores with npeet...\n",
      "Calculating Unique Relevance for all features with npeet...\n",
      "Unique Relevance calculation complete.\n",
      "Accuracy on Hill_Valley_with_noise: 0.9012345679012346\n",
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    10.20        0.0566905        3          0.87225         0.808153     19.12s\n",
      "   1     5.25          0.30615        3         0.871821         0.810431     27.70s\n",
      "   2     3.61         0.593796        5         0.871855         0.810868     27.45s\n",
      "   3     2.99         0.637031        3         0.872255         0.809717     22.57s\n",
      "   4     3.02         0.639057        3         0.872709         0.806619     19.04s\n",
      "   5     3.03         0.645104        3         0.872478         0.808516     14.06s\n",
      "   6     3.01         0.639833        3         0.872297         0.809115     12.91s\n",
      "   7     3.02         0.641791        3         0.872967           0.8001      6.97s\n",
      "   8     3.00         0.636016        3         0.872696         0.810855      4.08s\n",
      "   9     3.01         0.640456        3         0.873593         0.796542      0.00s\n",
      "Calculating Relevance scores with npeet...\n",
      "Calculating Unique Relevance for all features with npeet...\n",
      "Unique Relevance calculation complete.\n",
      "Accuracy on Hill_Valley_without_noise: 1.0\n",
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    11.48          0.15643       47         0.502381         0.496404      4.43m\n",
      "   1     4.19         0.303053        9         0.524111         0.506286      3.83m\n",
      "   2     3.39         0.353895        7         0.524288         0.520644      3.63m\n",
      "   3     4.12         0.404539       10         0.526008         0.536372      3.48m\n",
      "   4     3.49         0.438212        7         0.538606         0.542618      2.66m\n",
      "   5     3.98         0.415732        7         0.553772         0.543932      2.04m\n",
      "   6     4.08         0.399678        7         0.555941         0.524617      1.48m\n",
      "   7     4.22         0.401804        7         0.554486         0.537761     57.72s\n",
      "   8     5.07         0.409292       13         0.555699         0.525424     29.94s\n",
      "   9     6.76         0.412403        7         0.556898         0.515508      0.00s\n",
      "Calculating Relevance scores with npeet...\n",
      "Calculating Unique Relevance for all features with npeet...\n",
      "Unique Relevance calculation complete.\n",
      "Accuracy on adult: 0.8605793837649708\n",
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    12.63        0.0699936        6         0.328991         0.207221     36.62s\n",
      "   1     4.42         0.149205        6         0.333434         0.126344     35.88s\n",
      "   2     2.42         0.181346        6          0.33763        0.0953078     30.35s\n",
      "   3     3.32         0.186114        5          0.35761         0.158454     26.67s\n",
      "   4     5.79         0.193199        6         0.359887        0.0912038     24.34s\n",
      "   5     5.57         0.209188        6         0.366765         0.141957     19.77s\n",
      "   6     5.24         0.215777        5         0.368838        0.0596267     14.34s\n",
      "   7     5.13          0.24544        5          0.37464       0.00617411     10.37s\n",
      "   8     5.04         0.261312        5         0.367827        0.0949423      4.34s\n",
      "   9     5.02         0.261766        7         0.368802        0.0461236      0.00s\n",
      "Calculating Relevance scores with npeet...\n",
      "Calculating Unique Relevance for all features with npeet...\n",
      "Unique Relevance calculation complete.\n",
      "Accuracy on allhyper: 0.9814569536423841\n",
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    13.95         0.136633       15         0.393412         0.349001     16.49s\n",
      "   1     5.25         0.268074        6         0.411239         0.477202     28.46s\n",
      "   2     2.57         0.301822        4         0.405903         0.357311     20.77s\n",
      "   3     1.81          0.30964        1         0.399853         0.371643     20.36s\n",
      "   4     1.45         0.309854        3         0.401003         0.171647     17.37s\n",
      "   5     1.26         0.311025        3         0.406995         0.272918     12.12s\n",
      "   6     1.16         0.310994        3         0.418855         0.414428     10.36s\n",
      "   7     1.11          0.31194        1          0.40702         0.433979      6.01s\n",
      "   8     1.08         0.311818        1         0.396657         0.344092      3.36s\n",
      "   9     1.09         0.311563        1         0.417878         0.513152      0.00s\n",
      "Calculating Relevance scores with npeet...\n",
      "Calculating Unique Relevance for all features with npeet...\n",
      "Unique Relevance calculation complete.\n",
      "Accuracy on breast_cancer: 0.6896551724137931\n",
      "Running time: 1 day, 2:19:03.333120\n",
      "Accuracy of New Approach on allbp:0.9735099337748344\n",
      "Accuracy of New Approach on Hill_Valley_with_noise:0.9012345679012346\n",
      "Accuracy of New Approach on Hill_Valley_without_noise:1.0\n",
      "Accuracy of New Approach on adult:0.8605793837649708\n",
      "Accuracy of New Approach on allhyper:0.9814569536423841\n",
      "Accuracy of New Approach on breast_cancer:0.6896551724137931\n"
     ]
    }
   ],
   "source": [
    "new_approach_acc = []\n",
    "start_time = time.monotonic()\n",
    "\n",
    "for i in datasets:\n",
    "    new_approach_acc.append(new_approach_benchmark(i, SEED))\n",
    "\n",
    "end_time = time.monotonic()\n",
    "print(f\"Running time: {timedelta(minutes=end_time - start_time)}\")\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    print(f\"Accuracy of New Approach on {datasets[i]}:{new_approach_acc[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-method",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
